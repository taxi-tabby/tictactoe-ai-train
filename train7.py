import numpy as np
import tensorflow as tf
import os
import re
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, BatchNormalization, LeakyReLU, Reshape
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tqdm import tqdm  # ì§„í–‰ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# EarlyStopping ì„¤ì •
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)

def create_improved_model(input_shape):
    """
    ê° ì¹¸ì— í™•ë¥ ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ ìƒì„± í•¨ìˆ˜.
    ë” ë‹¤ì–‘í•œ ë°ì´í„°ì™€ ëª¨ë¸ ê°œì„ ì„ ë°˜ì˜í•œ êµ¬ì¡°
    """
    model = Sequential([

        Flatten(input_shape=input_shape),  # ì…ë ¥ ë°ì´í„°ë¥¼ 1Dë¡œ ë³€í™˜
        
        Dense(512),
        BatchNormalization(),
        LeakyReLU(alpha=0.1), 
        Dropout(0.5),  

        Dense(256),
        BatchNormalization(),
        LeakyReLU(alpha=0.1),
        Dropout(0.3), 
        
        Dense(64),
        BatchNormalization(),
        LeakyReLU(alpha=0.1),
        Dropout(0.1), 

        # ì¶œë ¥ ë ˆì´ì–´: ê° ì¹¸ì— ëŒ€í•œ í™•ë¥ ì„ ì˜ˆì¸¡
        Dense(input_shape[0] * input_shape[1], activation='softmax'),  # 3x3 í¬ê¸° ë³´ë“œì˜ ì˜ˆì¸¡
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    
    return model




# âœ… í´ë” ë‚´ì˜ íŒŒì¼ë“¤ì„ í™•ì¸í•˜ê³ , í•„ìš”í•œ ë°ì´í„°ë¥¼ ë¡œë”©
directory = './npy'
files = [f for f in os.listdir(directory) if f.endswith('.npy')]

# íŒ¨í„´ì„ ì´ìš©í•´ 'train_x'ì™€ 'train_y' íŒŒì¼ì„ ë§¤ì¹­
pattern = re.compile(r"train_(x|y)_(\d+)x(\d+)\.npy")

train_files = {'x': {}, 'y': {}}

# íŒŒì¼ ì´ë¦„ì—ì„œ x, y ë°ì´í„° ë¶„ë¦¬í•˜ì—¬ dictionaryì— ì €ì¥
for file in files:
    match = pattern.match(file)
    if match:
        file_type = match.group(1)  # 'x' ë˜ëŠ” 'y'
        x_size = int(match.group(2))  # x í¬ê¸°
        y_size = int(match.group(3))  # y í¬ê¸°
        shape = (x_size, y_size)
        
        # xì™€ y íŒŒì¼ì„ êµ¬ë¶„í•˜ì—¬ ì €ì¥
        if file_type == 'x':
            train_files['x'][shape] = file
        elif file_type == 'y':
            train_files['y'][shape] = file

# âœ… ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë£¨í”„
for shape in tqdm(train_files['x'].keys(), desc="Training Models"):

    x_file = train_files['x'].get(shape)
    y_file = train_files['y'].get(shape)

    # xì™€ y íŒŒì¼ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ ì§„í–‰
    if x_file and y_file:
        
        # âœ… Numpy íŒŒì¼ ë¡œë“œ
        train_x = np.load(os.path.join(directory, x_file))  # ë³´ë“œ ìƒíƒœ (3x3 í–‰ë ¬)
        train_y = np.load(os.path.join(directory, y_file))  # ìµœì ì˜ ìˆ˜ (ì •ìˆ˜ ë ˆì´ë¸”)

        # âœ… ë™ì ìœ¼ë¡œ ë³´ë“œ í¬ê¸° ì¶”ì¶œ
        x_size, y_size = train_x.shape[1], train_x.shape[2]  # x_size, y_sizeë¥¼ ë™ì ìœ¼ë¡œ ì¶”ì¶œ

        # train_y_reshaped = train_y.reshape(-1, x_size, y_size)
        # train_yë¥¼ (None, 9) í˜•íƒœë¡œ ë³€í™˜
        # train_y = train_y.reshape(-1, x_size*y_size)  # (None, 9) í˜•íƒœë¡œ reshape
        # train_y = train_y.reshape(-1, 3, 9)


        print(f"ğŸ”¹ ----------------------------------------------------------------------------------")
        print(f"ğŸ”¹ Model Training for size {x_size}x{y_size}")

        # âœ… CNN ì…ë ¥ í˜•ì‹ì— ë§ê²Œ reshape
        # train_x = train_x.astype('float32').reshape(-1, shape[0], shape[1], 1)  # CNN ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
        # train_xì™€ train_yëŠ” ì´ë¯¸ One-Hot ì¸ì½”ë”© ë˜ì–´ ìˆìŒ. ì¶”ê°€ ë³€í™˜ í•„ìš” ì—†ìŒ.

        # âœ… train_xì™€ train_yì˜ ê¸¸ì´ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        if train_x.shape[0] != train_y.shape[0]:
            print(f"âŒ train_x and train_y lengths do not match for shape {shape}: {train_x.shape[0]} vs {train_y.shape[0]}")
            continue  # ì´ ê²½ìš° í•´ë‹¹ í¬ê¸° ëª¨ë¸ í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤.

        print(f"ğŸ”¹ Model Training for size {shape}:")
        print(f"   train_x shape: {train_x.shape}")  
        print(f"   train_y shape: {train_y.shape}")  

        # âœ… ëª¨ë¸ ìƒì„±
        input_shape = train_x.shape[1:]  # (height, width, channels)

        # ë™ì ìœ¼ë¡œ ëª¨ë¸ ìƒì„±
        # model = create_improved_model(input_shape, train_y.shape[-1])  # num_classesëŠ” train_yì˜ ë§ˆì§€ë§‰ ì°¨ì›ì˜ í¬ê¸°
        model = create_improved_model(input_shape) 
        
        # ëª¨ë¸ í›ˆë ¨
        model.fit(train_x, (train_y), epochs=2000, batch_size=32, validation_split=0.0006, callbacks=[reduce_lr, early_stopping])
        
        # ëª¨ë¸ í‰ê°€
        loss, accuracy = model.evaluate(train_x, train_y)
        print(f"âœ… Model loss: {loss}, accuracy: {accuracy}")

        # ëª¨ë¸ ì €ì¥
        model_dir = './model'
        if not os.path.exists(model_dir):
            os.makedirs(model_dir)

        model_filename = f"tictactoe_model_{shape[0]}x{shape[1]}.h5"
        model.save(os.path.join(model_dir, model_filename))
        print(f"ğŸ¯ Model saved as '{model_filename}'")
    
    else:
        print(f"âŒ Missing x or y data for shape {shape}. Skipping...")

print("ğŸ‰ All models have been trained and saved.")
